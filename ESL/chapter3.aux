\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Supervised Learning}{1}{section.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Part I: Linear Regression}{1}{subsection.1.1}}
\newlabel{{eq:hypothesis_function}}{{1}{1}{Part I: Linear Regression}{equation.1.1}{}}
\newlabel{{eq:cost_function}}{{2}{1}{Part I: Linear Regression}{equation.1.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.1.1}LMS algorithm}{1}{subsubsection.1.1.1}}
\@writefile{toc}{\contentsline {paragraph}{gradient descent}{1}{section*.1}}
\newlabel{{eq:update_rule}}{{4}{1}{gradient descent}{equation.1.4}{}}
\@writefile{toc}{\contentsline {paragraph}{batch gradient descent}{1}{section*.2}}
\@writefile{toc}{\contentsline {paragraph}{stochastic gradient descent}{2}{section*.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}The normal equations}{2}{subsection.1.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.1}Matrix derivatives}{2}{subsubsection.1.2.1}}
\@writefile{toc}{\contentsline {paragraph}{$\nabla _A f(A)$}{2}{section*.4}}
\newlabel{{eq:gradient_definition}}{{5}{2}{$\nabla _A f(A)$}{equation.1.5}{}}
\@writefile{toc}{\contentsline {paragraph}{trace operation}{2}{section*.5}}
\newlabel{{eq:trace_definition}}{{6}{2}{trace operation}{equation.1.6}{}}
\newlabel{{eq:gradient_equations}}{{7}{2}{trace operation}{equation.1.7}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.2}Least squares revisited}{3}{subsubsection.1.2.2}}
\@writefile{toc}{\contentsline {paragraph}{design matrix}{3}{section*.6}}
\newlabel{{eq:design_matrix}}{{11}{3}{design matrix}{equation.1.11}{}}
\newlabel{{eq:target_values}}{{12}{3}{design matrix}{equation.1.12}{}}
\newlabel{{eq:normal_equation}}{{13}{4}{design matrix}{equation.1.13}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Statistical Learning}{4}{section.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Measuring the Quantity fit}{4}{subsection.2.1}}
\@writefile{toc}{\contentsline {paragraph}{Mean squared error}{4}{section*.7}}
\@writefile{toc}{\contentsline {paragraph}{degree of freedom}{4}{section*.8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}The Bias-Variance Trade-Off}{5}{subsection.2.2}}
\@writefile{toc}{\contentsline {paragraph}{Expected test MSE}{5}{section*.9}}
\@writefile{toc}{\contentsline {paragraph}{Variance}{5}{section*.10}}
\@writefile{toc}{\contentsline {paragraph}{bias}{5}{section*.11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}The Classification Setting}{5}{subsection.2.3}}
\@writefile{toc}{\contentsline {paragraph}{the training error rate}{5}{section*.12}}
\@writefile{toc}{\contentsline {paragraph}{The Bayes Classifier}{6}{section*.13}}
\@writefile{toc}{\contentsline {paragraph}{K-Nearest Neighbors}{6}{section*.14}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Classification}{6}{section.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Why Not Linear Regression?}{6}{subsection.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Logistic Regression}{7}{subsection.3.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Estimating the Regression Coefficients}{7}{subsection.3.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Linear Discriminant Analysis}{8}{subsection.3.4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.1}Using Bayes' Theorem for Classification}{8}{subsubsection.3.4.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.2}Linear Discriminant Analysis for p = 1}{8}{subsubsection.3.4.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.3}Linear Discriminant Analysis for p > 1}{9}{subsubsection.3.4.3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.4}Quadratic Discriminant Analysis}{9}{subsubsection.3.4.4}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Implementation - Python}{9}{section.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Classification}{9}{subsection.4.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.1}Machine Learning Basics}{9}{subsubsection.4.1.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.2}Classification with k-Nearest Neighbors}{9}{subsubsection.4.1.2}}
\@writefile{toc}{\contentsline {paragraph}{Prepare: Importing data with Python}{10}{section*.15}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Image Classification (CS231n)}{10}{section.5}}
\@writefile{toc}{\contentsline {paragraph}{Motivation}{10}{section*.16}}
\@writefile{toc}{\contentsline {paragraph}{Example}{10}{section*.17}}
\@writefile{toc}{\contentsline {paragraph}{Challenges}{10}{section*.18}}
\@writefile{toc}{\contentsline {paragraph}{Data-driven approach}{10}{section*.19}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}L1/L2 distance}{10}{subsection.5.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}k-Nearest Neighbor Classifier}{11}{subsection.5.2}}
\@writefile{toc}{\contentsline {paragraph}{Validation sets for Hyperparameter tuning}{11}{section*.20}}
\@writefile{toc}{\contentsline {paragraph}{Cross-validation}{11}{section*.21}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Linear Classification}{11}{subsection.5.3}}
\@writefile{toc}{\contentsline {paragraph}{Intro to Linear classification}{11}{section*.22}}
\@writefile{toc}{\contentsline {paragraph}{Linear score function}{12}{section*.23}}
\@writefile{toc}{\contentsline {subparagraph}{Linear classifier}{12}{section*.24}}
\@writefile{toc}{\contentsline {paragraph}{Interpreting a linear classifier}{12}{section*.25}}
\@writefile{toc}{\contentsline {paragraph}{Loss function}{12}{section*.26}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.1}Multiclass SVM}{13}{subsubsection.5.3.1}}
\@writefile{toc}{\contentsline {paragraph}{Regularization}{13}{section*.27}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.2}Softmax classifier}{13}{subsubsection.5.3.2}}
\@writefile{toc}{\contentsline {paragraph}{Practical issues: Numeric stability}{13}{section*.28}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.3}SVM vs Softmax}{14}{subsubsection.5.3.3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.4}Optional: Deep Learning using Linear Support Vector Machines}{14}{subsubsection.5.3.4}}
\@writefile{toc}{\contentsline {paragraph}{Multiclass SVMs}{14}{section*.29}}
\@writefile{toc}{\contentsline {paragraph}{Deep Learning with Support Vector Machines}{14}{section*.30}}
\@writefile{toc}{\contentsline {paragraph}{Experiment: Facial Expression Recognition}{15}{section*.31}}
