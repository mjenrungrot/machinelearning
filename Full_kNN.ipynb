{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will include all the codes that are needed to make a real classifier algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GUI stuff\n",
    "The following codes are very very important and needed to be processed individually before running an algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%gui qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%gui\n",
    "%gui wx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# This will make matplotlib figures show inline.\n",
    "%matplotlib inline  \n",
    "\n",
    "# This will make the notebook reload external python automatically.\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is for the parameters for plotting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) \n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input \n",
    "The following will be used for getting input from the CIFAR-10 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cPickle as pickle\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def load_CIFAR_batch(filename):\n",
    "    \"\"\" load a single batch of CIFAR\n",
    "    \"\"\"\n",
    "    with open(filename, 'rb') as f:\n",
    "        # Note that CIFAR-10 dataset is produced with cPickle.\n",
    "        datadict = pickle.load(f) \n",
    "        X = datadict['data']\n",
    "        Y = datadict['labels']\n",
    "        X = X.reshape(10000, 3, 32, 32).transpose(0,2,3,1).astype('float')\n",
    "        Y = np.array(Y)\n",
    "        return X,Y\n",
    "\n",
    "def load_CIFAR10(ROOT):\n",
    "    \"\"\" load all of CIFAR dataset\n",
    "    \"\"\"\n",
    "    xs = []\n",
    "    ys = []\n",
    "    for b in range(1,6):\n",
    "        f = os.path.join(ROOT, 'data_batch_%d' % (b, ))\n",
    "        X, Y = load_CIFAR_batch(f)\n",
    "        xs.append(X)\n",
    "        ys.append(Y)\n",
    "    Xtr = np.concatenate(xs)\n",
    "    Ytr = np.concatenate(ys)\n",
    "    del X,Y\n",
    "    Xte, Yte = load_CIFAR_batch(os.path.join(ROOT, 'test_batch'))\n",
    "    return Xtr, Ytr, Xte, Yte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "** This is the setting for the raw CIFAR-10 directory. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cifar10_dir = 'cifar-10-batches-py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will get the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can change the following code to check the shape of the dataset: "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print 'Training data shape: ', X_train.shape\n",
    "print 'Training labels shape: ', y_train.shape\n",
    "print 'Test data shape: ', X_test.shape\n",
    "print 'Test labels shape: ', y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization\n",
    "For this section, we will write code to visualize some random examples from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Visualize some examples from the dataset.\n",
    "# We show a few examples of training images from each class.\n",
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "num_classes = len(classes)\n",
    "samples_per_class = 7\n",
    "\n",
    "for y, cls in enumerate(classes):\n",
    "    idxs = np.flatnonzero(y_train == y)\n",
    "    idxs = np.random.choice(idxs, samples_per_class, replace=False)\n",
    "    for i, idx in enumerate(idxs):\n",
    "        # enumerate by column\n",
    "        plt_idx = i * num_classes + y + 1\n",
    "        plt.subplot(samples_per_class, num_classes, plt_idx)\n",
    "        plt.imshow(X_train[idx].astype('uint8'))\n",
    "        plt.axis('off')\n",
    "        if i == 0:\n",
    "            plt.title(cls)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L2 distance classifier \n",
    "In this section, we will use L2 distance as a classifier to classify the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We need to subsample the data for more efficient coude execution\n",
    "num_training = 5000\n",
    "mask = range(num_training)\n",
    "X_train = X_train[mask]\n",
    "y_train = y_train[mask]\n",
    "\n",
    "num_test = 500\n",
    "mask = range(num_test)\n",
    "X_test = X_test[mask]\n",
    "y_test = y_test[mask]\n",
    "\n",
    "# Then, we need to reshape the image data into rows.\n",
    "X_train = np.reshape(X_train,(X_train.shape[0], -1))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], -1))\n",
    "print X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would now like to classify the test data with the kNN classifier. Recall that we can break down this process into two steps: \n",
    "\n",
    "1. First we must compute the distances between all test examples and all train examples. \n",
    "2. Given these distances, for each test example we find the k nearest examples and have them vote for the label\n",
    "\n",
    "Lets begin with computing the distance matrix between all training and test examples. For example, if there are **Ntr** training examples and **Nte** test examples, this stage should result in a **Nte x Ntr** matrix where each element (i,j) is the distance between the i-th test and j-th train example.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class KNearestNeighbor:\n",
    "    \"\"\" a kNN classsifier with L2 distance\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def train(self, X, y):\n",
    "        \"\"\" Train the classifier. For k-nearest neighbors, \n",
    "            this is just memorizing the training data.\n",
    "            \n",
    "            Input:\n",
    "            X - A num_train x dimension array where each row \n",
    "                represents a single training point.\n",
    "            y - A vector of length num_train, where y[i] is the \n",
    "                label for X[i, :]\n",
    "        \"\"\"\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "        \n",
    "    def predict(self, X, k=1, num_loops=0):\n",
    "        \"\"\" Predict labels for test data using the classifier.\n",
    "        \n",
    "            Input:\n",
    "            X - A num_test x dimension array where each row represents\n",
    "                a single test point.\n",
    "            k - The number of nearest neighbors that vote for predicte\n",
    "                label.\n",
    "            num_loops - Determines which method to use to compute distances\n",
    "                        between training points and test points.\n",
    "        \n",
    "            Output:\n",
    "            y - A vector of length num_test, where y[i] represents the \n",
    "                predicted label for the test point X[i, :].\n",
    "        \"\"\"\n",
    "        if num_loops == 0:\n",
    "            dists = self.compute_distances_no_loops(X)\n",
    "        elif num_loops == 1:\n",
    "            dists = self.compute_distances_one_loop(X)\n",
    "        elif num_loops == 2:\n",
    "            dists = self.compute_distances_two_loops(X)\n",
    "        else:\n",
    "            raise ValueError('Invalid value %d for num_loops' % num_loops)\n",
    "        return self.predict_labels(dists,k=k)\n",
    "\n",
    "    def compute_distances_two_loops(self, X):\n",
    "        \"\"\" Compute the distance between each test point in X and each \n",
    "            training point in self.X_train using a nested loop over both \n",
    "            the training data and the test data.\n",
    "            \n",
    "            Input:\n",
    "            X - A num_test x dimension array where each row is a test point.\n",
    "            \n",
    "            Output:\n",
    "            dists - A num_test x num_train array where dists[i, j] gives\n",
    "                    the distance between the ith test point and the jth \n",
    "                    training point.\n",
    "        \"\"\"\n",
    "        num_test = X.shape[0]\n",
    "        num_train = self.X_train.shape[0]\n",
    "        dists = np.zeros((num_test,num_train))\n",
    "        for i in xrange(num_test):\n",
    "            for j in xrange(num_train):\n",
    "                dists[i,j] = np.sqrt(np.sum(np.square(X[i,:] - self.X_train[j,:])))\n",
    "        return dists\n",
    "    \n",
    "    def compute_distances_one_loop(self,X):\n",
    "        \"\"\" Same as compute_disances_two_loops; however, we will use just one \n",
    "            loop instead.\n",
    "        \"\"\"\n",
    "        num_test = X.shape[0]\n",
    "        num_train = self.X_train.shape[0]\n",
    "        dists = np.zeros((num_test,num_train))\n",
    "        for i in xrange(num_test):\n",
    "            dists[i,:] = np.sqrt(np.sum(np.square(X[i,:] - self.X_train),axis=1))\n",
    "        return dists\n",
    "    \n",
    "    def compute_distances_no_loops(self,X):\n",
    "        \"\"\" Same as compute_disances_two_loops; however, we will use just one \n",
    "            loop instead.\n",
    "        \"\"\"\n",
    "        X2 = np.dot(X**2,np.ones(self.X_train.shape).T)\n",
    "        XY = np.dot(X,self.X_train.T)\n",
    "        Y2 = np.dot(np.ones(X.shape),self.X_train.T**2)\n",
    "        dists = X2 - 2*XY + Y2\n",
    "        del X2,XY,Y2\n",
    "        return dists\n",
    "    \n",
    "    def predict_labels(self, dists, k=1):\n",
    "        \"\"\" Given a matrix of distances between test points and training \n",
    "            points, predict a label for each test point.\n",
    "            \n",
    "            Input:\n",
    "            dists - A num_test x num_train array where dists[i, j] gives\n",
    "                    the distance between the ith test point and the jth \n",
    "                    training point.\n",
    "            Output:\n",
    "            y - A vector of length num_test where y[i] represents the \n",
    "                predicted label for the ith test point.\n",
    "        \"\"\"\n",
    "        num_test = dists.shape[0]\n",
    "        y_pred = np.zeros(num_test)\n",
    "        for i in xrange(num_test):\n",
    "            # closest_y is a list of length k storing the labels for\n",
    "            # the k nearest neighbors to the ith test points\n",
    "            order = np.argsort(np.array(dists[i,:]))[:k]\n",
    "            closest_y = [self.y_train[y] for y in order]\n",
    "            \n",
    "            hashmap = {}\n",
    "            for y in closest_y:\n",
    "                if y in hashmap.keys():\n",
    "                    hashmap[y] += 1\n",
    "                else:\n",
    "                    hashmap[y] = 1\n",
    "            maxval = -1\n",
    "            maxidx = 1e9\n",
    "            for y in closest_y:\n",
    "                if hashmap[y] > maxval:\n",
    "                    maxval = hashmap[y]\n",
    "                    maxidx = y\n",
    "                elif hashmap[y] == maxval and y < maxidx:\n",
    "                    maxidx = y\n",
    "                    \n",
    "            y_pred[i] = maxidx\n",
    "            del hashmap, order, closest_y\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifier = KNearestNeighbor()\n",
    "classifier.train(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dists = classifier.compute_distances_two_loops(X_test)\n",
    "print dists.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Visualize the distance matrix: each row is a single test example\n",
    "# and its distances to trianing examples\n",
    "plt.imshow(dists, interpolation='none')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inline Question #1:** Notice the structured patterns in the distance matrix. \n",
    "\n",
    "- What is the cause behind the distinctly visible rows? \n",
    "- What causes the columns?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**: \n",
    "- The white row tends to visually imply that single test example is away from others so that it can form its own cluster.\n",
    "- The white column visually shows that paramater is significantly important in distinguishing the examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_test_pred = classifier.predict_labels(dists, k=1)\n",
    "\n",
    "num_correct = np.sum(y_test_pred == y_test)\n",
    "accuracy = float(num_correct) / num_test\n",
    "print 'Got %d / %d correct => accuracy: %f' % (num_correct, num_test, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now lets speed up distance matrix computation by using partial vectorization\n",
    "# with one loop. Implement the function compute_distances_one_loop and run the\n",
    "# code below:\n",
    "dists_one = classifier.compute_distances_one_loop(X_test)\n",
    "\n",
    "# To ensure that our vectorized implementation is correct, we make sure that it\n",
    "# agrees with the naive implementation. There are many ways to decide whether\n",
    "# two matrices are similar; one of the simplest is the Frobenius norm. In case\n",
    "# you haven't seen it before, the Frobenius norm of two matrices is the square\n",
    "# root of the squared sum of differences of all elements; in other words, reshape\n",
    "# the matrices into vectors and compute the Euclidean distance between them.\n",
    "difference = np.linalg.norm(dists - dists_one, ord='fro')\n",
    "print 'Difference was: %f' % (difference, )\n",
    "if difference < 0.001:\n",
    "  print 'Good! The distance matrices are the same'\n",
    "else:\n",
    "  print 'Uh-oh! The distance matrices are different'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now we will implement the fully vectorized version inside compute_distance_no_loops\n",
    "# and run the code\n",
    "dists_two = classifier.compute_distances_no_loops(X_test)\n",
    "\n",
    "# check if the distance matrix agrees with the one already computed\n",
    "# difference = np.linalg.norm(dists - dists_two, ord='fro')\n",
    "print 'Difference was: %f' % (difference, )\n",
    "if difference < 0.001:\n",
    "  print 'Good! The distance matrices are the same'\n",
    "else:\n",
    "  print 'Uh-oh! The distance matrices are different'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now, let's see how fast the vectorizations are.\n",
    "def time_function(f, *args):\n",
    "    \"\"\" Call a function f with args and return the time (in seconds)\n",
    "        that it took to execute.\n",
    "    \"\"\"\n",
    "    import time\n",
    "    tic = time.time()\n",
    "    f(*args)\n",
    "    toc = time.time()\n",
    "    return toc - tic\n",
    "\n",
    "two_loop_time = time_function(classifier.compute_distances_two_loops, X_test)\n",
    "print 'Two loop version took %f seconds' % two_loop_time\n",
    "\n",
    "one_loop_time = time_function(classifier.compute_distances_one_loop, X_test)\n",
    "print 'One loop version took %f seconds' % one_loop_time\n",
    "\n",
    "no_loop_time = time_function(classifier.compute_distances_no_loops, X_test)\n",
    "print 'No loop version took %f seconds' % no_loop_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation\n",
    "\n",
    "We have implemented the k-Nearest Neighbor classifier but we set the value k = 5 arbitrarily. We will now determine the best value of this hyperparameter with cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 10000, 3072) (5, 10000)\n",
      "k = 1, accuracy = 0.335800\n",
      "k = 1, accuracy = 0.336100\n",
      "k = 1, accuracy = 0.346900\n",
      "k = 1, accuracy = 0.334600\n",
      "k = 1, accuracy = 0.338300\n",
      "k = 3, accuracy = 0.324400\n",
      "k = 3, accuracy = 0.326100\n",
      "k = 3, accuracy = 0.328000\n",
      "k = 3, accuracy = 0.325200\n",
      "k = 3, accuracy = 0.317800\n",
      "k = 5, accuracy = 0.325500\n",
      "k = 5, accuracy = 0.329700\n",
      "k = 5, accuracy = 0.333600\n",
      "k = 5, accuracy = 0.334000\n",
      "k = 5, accuracy = 0.328300\n",
      "k = 8, accuracy = 0.334000\n",
      "k = 8, accuracy = 0.328300\n",
      "k = 8, accuracy = 0.334100\n",
      "k = 8, accuracy = 0.330700\n",
      "k = 8, accuracy = 0.323000\n",
      "k = 10, accuracy = 0.335800\n",
      "k = 10, accuracy = 0.325200\n",
      "k = 10, accuracy = 0.333000\n",
      "k = 10, accuracy = 0.333200\n",
      "k = 10, accuracy = 0.324300\n",
      "k = 12, accuracy = 0.335200\n",
      "k = 12, accuracy = 0.323600\n",
      "k = 12, accuracy = 0.328100\n",
      "k = 12, accuracy = 0.329400\n",
      "k = 12, accuracy = 0.323900\n",
      "k = 15, accuracy = 0.335200\n",
      "k = 15, accuracy = 0.323500\n",
      "k = 15, accuracy = 0.328400\n",
      "k = 15, accuracy = 0.327300\n",
      "k = 15, accuracy = 0.321500\n",
      "k = 20, accuracy = 0.330700\n",
      "k = 20, accuracy = 0.320400\n",
      "k = 20, accuracy = 0.325700\n",
      "k = 20, accuracy = 0.324800\n",
      "k = 20, accuracy = 0.314500\n",
      "k = 50, accuracy = 0.320300\n",
      "k = 50, accuracy = 0.308900\n",
      "k = 50, accuracy = 0.314900\n",
      "k = 50, accuracy = 0.311500\n",
      "k = 50, accuracy = 0.304200\n",
      "k = 100, accuracy = 0.308400\n",
      "k = 100, accuracy = 0.290200\n",
      "k = 100, accuracy = 0.300400\n",
      "k = 100, accuracy = 0.298900\n",
      "k = 100, accuracy = 0.294600\n"
     ]
    }
   ],
   "source": [
    "num_folds = 5\n",
    "k_choices = [1, 3, 5, 8, 10, 12, 15, 20, 50, 100]\n",
    "\n",
    "# We'll split up the input into num_folds partition to do cross-validation.\n",
    "X_train_folds = np.array(np.array_split(X_train,num_folds))\n",
    "y_train_folds = np.array(np.array_split(y_train,num_folds))\n",
    "\n",
    "print X_train_folds.shape, y_train_folds.shape\n",
    "\n",
    "# A dictionary holding the accuracies for different values of k that we find\n",
    "# when running cross-validation. After running cross-validation,\n",
    "# k_to_accuracies[k] should be a list of length num_folds giving the different\n",
    "# accuracy values that we found when using that value of k.\n",
    "k_to_accuracies = {}\n",
    "\n",
    "for k in k_choices:\n",
    "    accuracy = []\n",
    "    for i in xrange(num_folds):\n",
    "        classifier = KNearestNeighbor()\n",
    "        \n",
    "#         print \"shape = \" + str(X_train_folds[1].shape)\n",
    "        if i == 0:\n",
    "            X_train_folds_tmp = X_train_folds[1]\n",
    "            y_train_folds_tmp = y_train_folds[1]\n",
    "        else:\n",
    "            X_train_folds_tmp = X_train_folds[0]\n",
    "            y_train_folds_tmp = y_train_folds[0]\n",
    "        \n",
    "        for j in xrange(1,num_folds):\n",
    "            if i != j:\n",
    "                X_train_folds_tmp = np.concatenate((X_train_folds_tmp,X_train_folds[j]))\n",
    "                y_train_folds_tmp = np.concatenate((y_train_folds_tmp,y_train_folds[j]))\n",
    "#         print X_train_folds_tmp.shape, y_train_folds_tmp.shape\n",
    "        classifier.train(X_train_folds_tmp, y_train_folds_tmp)\n",
    "        \n",
    "        dists = classifier.compute_distances_no_loops(X_train_folds[i])\n",
    "        y_test_pred = classifier.predict_labels(dists, k)\n",
    "        \n",
    "        num_correct = np.sum(y_test_pred == y_train_folds[i])\n",
    "        acc = float(num_correct) / float(len(y_train_folds[i]))\n",
    "        accuracy.append(acc)\n",
    "    k_to_accuracies[k] = accuracy\n",
    "\n",
    "# Check the accuracies\n",
    "for k in sorted(k_to_accuracies):\n",
    "    for accuracy in k_to_accuracies[k]:\n",
    "        print 'k = %d, accuracy = %f' % (k, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAm8AAAH4CAYAAAAcvQruAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x111a9cd50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the raw observations\n",
    "for k in k_choices:\n",
    "    accuracy = k_to_accuracies[k]\n",
    "    plt.scatter([k] * len(accuracy), accuracy)\n",
    "\n",
    "# plot the trend line\n",
    "accuracy_mean = np.array([np.mean(v) for k,v in sorted(k_to_accuracies.items())])\n",
    "accuracy_std = np.array([np.std(v) for k,v in sorted(k_to_accuracies.items())])\n",
    "plt.errorbar(k_choices, accuracy_mean, yerr=accuracy_std)\n",
    "plt.title('Cross-validation on k')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Cross-validation accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 3118 / 10000 correct => accuracy: 0.311800\n"
     ]
    }
   ],
   "source": [
    "# Based on the cross-validation results above, choose the best value for k,   \n",
    "# retrain the classifier using all the training data, and test it on the test\n",
    "# data.\n",
    "best_k = 100\n",
    "\n",
    "X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n",
    "X_train = np.reshape(X_train,(X_train.shape[0], -1))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], -1))\n",
    "\n",
    "classifier = KNearestNeighbor()\n",
    "classifier.train(X_train, y_train)\n",
    "y_test_pred = classifier.predict(X_test, k=best_k)\n",
    "\n",
    "# Compute and display the accuracy\n",
    "num_correct = np.sum(y_test_pred == y_test)\n",
    "num_test = float(len(y_test_pred))\n",
    "accuracy = float(num_correct) / num_test\n",
    "print 'Got %d / %d correct => accuracy: %f' % (num_correct, num_test, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
